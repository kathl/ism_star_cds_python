{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing CDS services with Python \n",
    "## ISM*@ST on 24/08/20\n",
    "\n",
    "Katharina Lutz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we get started\n",
    "### More resources \n",
    "This is a collection of links, where you can find more information:\n",
    " - Relevant Python Packages:\n",
    "     - [`astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "     - [`pyVO`](https://pyvo.readthedocs.io/en/latest/#)\n",
    "     - [`MOCpy`](https://cds-astro.github.io/mocpy/)\n",
    "     - [`ipyaladin`](https://github.com/cds-astro/ipyaladin)\n",
    " - AstroBetter posts on: [ipyaladin](https://www.astrobetter.com/blog/2020/05/04/the-cds-and-python-i-explore-the-sky-with-ipyaladin/), [MOCs](https://www.astrobetter.com/blog/2020/06/01/the-cds-and-python-ii-to-cover-or-not-to-cover-mocs-to-the-rescue/), [VizieR & XMatch](https://www.astrobetter.com/blog/2020/06/29/the-cds-and-python-iii-vizier-xmatch-20k-catalogues-and-tables-at-your-fingertips/) and [SIMBAD](https://www.astrobetter.com/blog/2020/07/06/the-cds-and-python-iv-simbad-the-yellow-pages-of-astronomical-sources/)\n",
    " - [Classic VO tutorials](http://www.euro-vo.org/index25a9.html?q=science/scientific-tutorials) translated to [Python](https://github.com/cds-astro/tutorials) (in progress)\n",
    " \n",
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy import coordinates\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "import astropy.visualization as ap_vis\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.cds import cds\n",
    "from astroquery.simbad import Simbad\n",
    "\n",
    "import pyvo\n",
    "\n",
    "import ipyaladin.aladin_widget as ipyal\n",
    "import mocpy\n",
    "from urllib.parse import quote\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of CDS services\n",
    "\n",
    " - <img src=\"Images/logo_simbad.png\" alt=\"SIMBAD\" style=\"width:40px; display: inline-block;\"/> **SIMBAD**: <br>\n",
    " a bibliographic database containing interesting astronomical objects that have been studied in the literature. Look here for information on single objects, where are they located, what type of object is it, which paper mentions this object? <br>\n",
    " $\\rightarrow$ **`astroquery.simbad`** and **`pyVO`**\n",
    " - <img src=\"Images/logo_vizier.png\" alt=\"VizieR\" style=\"width:40px; display: inline-block;\"/> **VizieR**: <br>\n",
    " a database of catalogues and tables and their associated data. VizieR hosts both reference catalogues from large surveys at all wavelengths (2MASS, GAIA, NVSS, ...) and tables from papers. In addition data (images or spectra) associated with some tables are also provided. <br>\n",
    " $\\rightarrow$ **`astroquery.vizier`** and **`pyVO`**\n",
    " - <img src=\"Images/xmatch2.png\" alt=\"XMatch\" style=\"width:40px; display: inline-block;\"/> **XMatch**: <br>\n",
    " quick spatial cross matches between tables. These could be your own tables, any VizieR table or all of SIMBAD. <br>\n",
    " $\\rightarrow$ **`astroquery.xmatch`**\n",
    " - <img src=\"Images/logo_aladin.png\" alt=\"Aladin\" style=\"width:40px; display: inline-block;\"/> **Aladin & AladinLite**: <br>\n",
    " simple and fast acces to all large imaging surveys, which are provided in the form of HiPS.  <br>\n",
    " $\\rightarrow$ **`ipyaladin`** (in development **`hips2fits`**)\n",
    " - **MOC**: <br>\n",
    " coverage maps, which allow for description of arbitrary patches on the sky, and quick unions or intersections inbetween these patches.  <br>\n",
    " $\\rightarrow$  **`MOCpy`** and **`astroquery.cds`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cautionary note before we get started:\n",
    "Running queries in a loop might make our servers feel like you are attempting a DDoS attack ;) The `query_region` functions in the `astroquery` modules usually take lists of coordinates as input. An other option is to add a little `time.sleep(3)` in your loop, which makes the script wait between each step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Science setting for today\n",
    "We are looking for galaxies sufficient auxiliary data to study the distribution of the dust to atomic gas ratio. \n",
    "\n",
    "The steps we are going to take are the following:\n",
    " - Find all those galaxies that are within the observing footprints of GALEX, DES or SDSS, WISE and Herschel.\n",
    " - Quickly visualise these galaxies and their location on the sky\n",
    " - Pick one of these galaxies and get tabular data from VizieR for this galaxy\n",
    " - Pick one of these galaxies and search the associated data in the VizieR for HI data\n",
    " - Compile a list of bibliographic references for this galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coverage maps and compute their interesection\n",
    "First we get the multiorder coverage (MOC) maps of different surveys. These MOCs can be used to describe any arbitrary patch on the sky. You could actually create MOCs just based on [polygons](https://cds-astro.github.io/mocpy/stubs/mocpy.MOC.html#mocpy.MOC.from_polygon) or your favourite [set of images](https://cds-astro.github.io/mocpy/stubs/mocpy.MOC.html#mocpy.MOC.from_fits_images), but here we are interested in the footprints of particular surveys or observations. These MOCs are stored on the CDS MOCServer and can be obtained with the `astroquery.cds` module. \n",
    "\n",
    "We know we want FUV imaging data from GALEX and F475W imaging data from HST, but we don't know what the data sets are called. So we first query the MOC server to get metadata for all data sets, which have IDs that contain some buzzwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_galex = cds.find_datasets(meta_data=\"ID=*GALEX*\")\n",
    "info_herschel = cds.find_datasets(meta_data=\"ID=*HERSCHEL*\")\n",
    "info_wise = cds.find_datasets(meta_data=\"ID=*WISE*\")\n",
    "info_des = cds.find_datasets(meta_data=\"ID=*DES*\")\n",
    "info_sdss = cds.find_datasets(meta_data=\"ID=*SDSS*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you get a lot of meta data for each of these datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_galex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time being we are just happy to see the ID and and a descriptopn of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info_galex['ID', 'obs_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info_herschel['ID', 'obs_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_wise['ID', 'obs_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_des['ID', 'obs_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sdss['ID', 'obs_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, new we know more about these datasets, let's get their coverage map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc_galex = cds.find_datasets(meta_data=\"ID=CDS/P/GALEXGR6/AIS/*UV\", return_moc=True)\n",
    "moc_sdss = cds.find_datasets(meta_data=\"ID=CDS/P/SDSS9/*\", return_moc=True)\n",
    "moc_wise = cds.find_datasets(meta_data=\"ID=CDS/P/allWISE/W*\", return_moc=True)\n",
    "moc_pacs = cds.find_datasets(meta_data=\"ID=ESAVO/P/HERSCHEL/PACS*\", return_moc=True)\n",
    "moc_spire = cds.find_datasets(meta_data=\"ID=ESAVO/P/HERSCHEL/SPIRE*\", return_moc=True)\n",
    "moc_des = cds.find_datasets(meta_data=\"ID=CDS/P/DES-DR1/*\", return_moc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc_dict = {'GALEX': moc_galex, 'SDSS': moc_sdss, \n",
    "            'WISE': moc_wise, 'PACS': moc_pacs, 'SPIRE': moc_spire, \n",
    "            'DES': moc_des}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can visualise these coverage maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for survey in moc_dict.keys():\n",
    "    fig = plt.figure(figsize=(6.3, 5.0))\n",
    "    with mocpy.World2ScreenMPL(fig, \n",
    "             fov=200 * u.deg,\n",
    "             center=coordinates.SkyCoord(0, 20, unit='deg', frame='icrs'),\n",
    "             coordsys=\"icrs\",\n",
    "             rotation=coordinates.Angle(0, u.degree),\n",
    "             projection=\"AIT\") as wcs:\n",
    "        ax = fig.add_axes([0.17, 0.17, 0.77, 0.77], projection=wcs)\n",
    "        moc_dict[survey].fill(ax=ax, wcs=wcs, alpha=0.5, fill=True, color=\"crimson\")\n",
    "        ax.set_xlabel('RA')\n",
    "        ax.set_ylabel('Dec')\n",
    "        lon, lat = ax.coords[0], ax.coords[1]\n",
    "        lon.set_major_formatter('hh:mm:ss')\n",
    "        lat.set_major_formatter('dd:mm')\n",
    "        lon.set_ticklabel(exclude_overlapping=True)\n",
    "        lat.set_ticklabel(exclude_overlapping=True)\n",
    "        lon.set_ticks(spacing=2 * u.hourangle)\n",
    "        ax.coords.grid(color='black', linestyle='solid', alpha=0.5)\n",
    "        ax.text(0.03, 0.03, survey, color='black', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our idea was to get those regions on the sky that are either observed by SDSS or DES AND that are observed by all other surveys. To describe these regions with MOCs, we first build the union of SDSS and DES and then calculate the intersection between all remaining surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc_final = moc_sdss.union(moc_des)\n",
    "for survey in moc_dict.keys():\n",
    "    if survey in ['SDSS', 'DES']: \n",
    "        continue\n",
    "    print('Forming intersection with: ', survey)\n",
    "    moc_final = moc_final.intersection(moc_dict[survey])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and just a final look at the resulting shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.3, 5.0))\n",
    "with mocpy.World2ScreenMPL(fig, \n",
    "         fov=200 * u.deg,\n",
    "         center=coordinates.SkyCoord(0, 20, unit='deg', frame='icrs'),\n",
    "         coordsys=\"icrs\",\n",
    "         rotation=coordinates.Angle(0, u.degree),\n",
    "         projection=\"AIT\") as wcs:\n",
    "    ax = fig.add_axes([0.17, 0.17, 0.77, 0.77], projection=wcs)\n",
    "    moc_final.fill(ax=ax, wcs=wcs, alpha=0.5, fill=True, color=\"darkcyan\")\n",
    "    ax.set_xlabel('RA')\n",
    "    ax.set_ylabel('Dec')\n",
    "    lon, lat = ax.coords[0], ax.coords[1]\n",
    "    lon.set_major_formatter('hh:mm:ss')\n",
    "    lat.set_major_formatter('dd:mm')\n",
    "    lon.set_ticklabel(exclude_overlapping=True)\n",
    "    lat.set_ticklabel(exclude_overlapping=True)\n",
    "    lon.set_ticks(spacing=2 * u.hourangle)\n",
    "    ax.coords.grid(color='black', linestyle='solid', alpha=0.5)\n",
    "    ax.text(0.03, 0.03, 'Final MOC', color='black', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that is a bit patchy, but this describes the regions on the sky we wanted and MOC is a great way to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a catalogue from VizieR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_list_dustpedia = Vizier.find_catalogs('Dustpedia')\n",
    "for k, v in catalog_list_dustpedia.items():\n",
    "    print(k, ': ', v.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizir_dustpedia = Vizier(row_limit=-1)\n",
    "results = vizir_dustpedia.get_catalogs('J/A+A/609/A37')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of `astropy` tables , which you can just use as any other `astropy` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dustpedia_sample = results[0]\n",
    "dustpedia_sample['Name', 'RAJ2000', 'DEJ2000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since positions of the galaxies in Dustpedia are given in the catalogue we can filter the catalogue to only show galaxies within the MOC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indexes = moc_final.contains(dustpedia_sample['RAJ2000'].T * u.deg, \n",
    "                             dustpedia_sample['DEJ2000'].T * u.deg)\n",
    "filtered_dustpedia = dustpedia_sample[indexes]\n",
    "filtered_dustpedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can query Vizier only within the MOC. (Currently this functionality is located within the MOCPy package but it might move over to astroquery at some point.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_dustpedia_2 = moc_final.query_vizier_table('J/A+A/609/A37/sample', max_rows=100000)\n",
    "filtered_dustpedia_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick recap in between: we have seen, how we can\n",
    " - check the spatial coverage of different surveys. \n",
    " - find intersections and unions of these coverage maps. \n",
    " - find tables in VizieR.\n",
    " - download tables from VizieR.\n",
    " - filter tables to find those entries that are located within a MOC. \n",
    " \n",
    "## Visualise sources\n",
    "\n",
    "One option is the AladinLite widget for Jupyter notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aladin= ipyal.Aladin(survey='cds/P/DES-DR1/ColorIRG', target='NGC289', fov=0.5)\n",
    "aladin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aladin.add_table(filtered_dustpedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aladin.target = 'M101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to use HiPS, which Josh mentioned the other day. HiPS is a way of organising image, cube and catalogue data in a hierarchical way. The main principle is, the more you zoom in the more you see. All the surveys shown in the AladinLite widget above are organised as HiPS. Since all HiPS are saved in Healpix format getting cutouts is quite easy. There is a [webpage](http://alasky.u-strasbg.fr/hips-image-services/hips2fits), which has more information and a module in astroquery is under development. For the time being, we can use the following workaround:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_hips = {'DES g': 'CDS/P/DES-DR1/g', 'GALEX FUV': 'CDS/P/GALEXGR6/AIS/FUV', \n",
    "                 'WISE W4': 'CDS/P/allWISE/W4', 'Spire 500mu': 'ESAVO/P/HERSCHEL/SPIRE-500', \n",
    "                 'PACS 100mu': 'ESAVO/P/HERSCHEL/PACS100'}\n",
    "# Field of view in deg, here we want 7arcmin\n",
    "fov = 7.0 / 60.\n",
    "# Numbers of pixel with pixelsize of 0.6 arcsec\n",
    "width = int(round(fov * 3600. / 0.6))\n",
    "height = int(round(fov * 3600. / 0.6))\n",
    "# Central coordinates \n",
    "sc = coordinates.SkyCoord(ra=13.17645, dec=-31.20581, unit=u.deg)\n",
    "ra = sc.icrs.ra.deg\n",
    "dec = sc.icrs.dec.deg\n",
    "\n",
    "interval = ap_vis.AsymmetricPercentileInterval(1.0, 99.9)\n",
    "\n",
    "for survey in selected_hips.keys():\n",
    "    # get the image\n",
    "    hips = selected_hips[survey]\n",
    "    url = 'http://alasky.u-strasbg.fr/hips-image-services/hips2fits?' + \\\n",
    "          'hips={0}&width={1:d}&height={2:d}&fov={3:.4f}&'.format(quote(hips), width, height, fov)  + \\\n",
    "          'projection=TAN&coordsys=icrs&ra={0:.5f}&dec={1:.5f}'.format(ra, dec)\n",
    "    ima = fits.open(url)\n",
    "    \n",
    "    # plot the image\n",
    "    wcs = WCS(ima[0].header)\n",
    "    fig = plt.figure(figsize=(6.3, 5.0))\n",
    "    ax = fig.add_axes([0.17, 0.17, 0.77, 0.77], \n",
    "                      projection=wcs)\n",
    "    vmin, vmax = interval.get_limits(ima[0].data)\n",
    "    ax.imshow(ima[0].data, origin='lower',\n",
    "              vmin=vmin, vmax=vmax, \n",
    "              cmap=mpl.cm.magma_r)\n",
    "    # take care of axis labels ect.\n",
    "    imsize = fov / (ima[0].header['CDELT2'])\n",
    "    central_pix = wcs.wcs_world2pix(np.array([[ra], [dec]]).T, 0)\n",
    "    ax.set_ylim(central_pix[0][1] - 0.5 * imsize,\n",
    "                central_pix[0][1] + 0.5 * imsize)\n",
    "    ax.set_xlim(central_pix[0][0] - 0.5 * imsize,\n",
    "                central_pix[0][0] + 0.5 * imsize)\n",
    "    lon, lat = ax.coords[0], ax.coords[1]\n",
    "    lon.set_major_formatter('hh:mm:ss')\n",
    "    lat.set_major_formatter('dd:mm')\n",
    "    lon.set_ticklabel(exclude_overlapping=True)\n",
    "    lat.set_ticklabel(exclude_overlapping=True)\n",
    "    ax.set_xlabel('RA (J2000)')\n",
    "    ax.set_ylabel('Dec (J2000)')\n",
    "    ax.text(0.05, 0.05, '{}'.format(survey), color='black',\n",
    "            transform=ax.transAxes)\n",
    "    # save the image and close it\n",
    "    ima.writeto('test_{}.fits'.format(survey), overwrite=True)\n",
    "    ima.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still relavtively new technology and things are evolving. But for the time being I found it useful to visualise stars and HI in [150 galaxies](https://www.youtube.com/watch?v=aIWlsOf-mA0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing associated data in VizieR \n",
    "Associated data in VizieR are images, spectra or data cubes that are associated to a table in VizieR and are likely the basis of some of the measurement given in this table. If you use the VizieR web interface, a symbol will tell you whether a catalogue comes with associated data:\n",
    "\n",
    "<img src=\"Images/vizier_assoc_data.png\"/>\n",
    "\n",
    "There is also a dedicated [webpage](http://cdsarc.u-strasbg.fr/assocdata/) to search through the associated data. However, here we want to use the power of pyVO to search for associated data for NGC289, the galaxy we already looked at above. \n",
    "\n",
    "Before we get into more details, let me take a minute to tell you a bit more about accessing tables in the framework of the Virtual Observatory: within the VO you can use the Table Access Protocol (TAP) to query tables. TAP is implemented in pyVO and you just need to give it the location of the server. Once the server is declared you can use ADQL, which is a flavour of SQL to query tables and databases which are located on the server. So let's see whether we can find associated data in the vicinity of NGC289.\n",
    "\n",
    "First declare the server location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_vizier = pyvo.dal.TAPService('http://tapvizier.u-strasbg.fr/TAPVizieR/tap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then build the query. VizieR has a couple of databases you can query: \n",
    " - there is a database of all tables in VizieR (`tables`), which you can use to find the right table.\n",
    " - each table can be queried (e.g. `J/A+A/609/A37/sample`). \n",
    " - there is a database of all associated data (`\"B/assocdata/obscore\"`), which contains meta data for each image, spectrum, ect. This is the one we want to query here.\n",
    "\n",
    "To better understand the table we are going to query, we'll just have a look at the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_string = \"SELECT TOP 5 * FROM \\\"B/assocdata/obscore\\\" \"\n",
    "top5obscore = tap_vizier.search(query_string)\n",
    "top5obscore.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we get a lot of meta data, you can query for the location of the data (`RAJ2000` and `DEJ2000`) or the parent VizieR table for which we know the the name (`obs_collection`).\n",
    "This time we just look for all data at radio wavelengths (between 0.1 and 1m in wavelengths), which were observed with the ATCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"SELECT * \" + \\\n",
    "               \"FROM \\\"B/assocdata/obscore\\\" \" + \\\n",
    "               \"WHERE em_min >= 0.01 AND em_max <= 1.0 AND facility_name='ATCA'\"\n",
    "ATCA_assoc_data = tap_vizier.search(query_string)\n",
    "ATCA_assoc_data.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now once more we can filter this list of potential HI observations by the MOC of complementary multi wavelength observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = moc_final.contains(ATCA_assoc_data.to_table()['RAJ2000'].T * u.deg, \n",
    "                             ATCA_assoc_data.to_table()['DEJ2000'].T * u.deg)\n",
    "filtered_assoc_data = ATCA_assoc_data.to_table()[indexes]\n",
    "filtered_assoc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_data = fits.open('http://cdsarc.u-strasbg.fr/saadavizier/download?oid=864974549052030995')\n",
    "assoc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs = WCS(assoc_data[0].header).celestial\n",
    "fig = plt.figure(figsize=(6.3, 5.04))\n",
    "ax = fig.add_axes([0.17, 0.17,\n",
    "                   0.77, 0.77], projection=wcs)\n",
    "ax.imshow(assoc_data[0].data[150, :, :], cmap='gist_gray_r')\n",
    "ax.contour(assoc_data[0].data[150, :, :], colors='crimson', linewidths=0.5)\n",
    "ax.set_xlabel('RAJ2000')\n",
    "ax.set_ylabel('DEJ2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.max(assoc_data[0].data, axis=(1,2))\n",
    "fig = plt.figure(figsize=(6.3, 5.04))\n",
    "ax = fig.add_axes([0.17, 0.17, 0.77, 0.77])\n",
    "ax.plot(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila a beautiful HI double horn, which we can use for further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
